{
  "metadata": {
    "kernelspec": {
      "name": "xpython",
      "display_name": "Python 3.13 (XPython)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "46ae3c59-ff30-481e-bc64-79f47397a2bc",
      "cell_type": "code",
      "source": "# ----------------------------\n# 1. IMPORT LIBRARIES\n# ----------------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport warnings\nwarnings.filterwarnings('ignore')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0fdcd58d-929e-4fce-b313-eb99057faf5a",
      "cell_type": "code",
      "source": "# ----------------------------\n# 2. LOAD AND PREPROCESS DATA\n# ----------------------------\ndf = pd.read_csv('CarPrice_Assignment.csv')\n\n# Extract brand from CarName (clean and standardize)\ndf['CarName'] = df['CarName'].str.lower().str.strip()\ndf['brand'] = df['CarName'].apply(lambda x: x.split()[0])\n\n# Fix common brand typos\ntypos = {\n    'maxda': 'mazda',\n    'porcshce': 'porsche',\n    'toyouta': 'toyota',\n    'vokswagen': 'volkswagen',\n    'vw': 'volkswagen'\n}\ndf['brand'] = df['brand'].replace(typos)\n\n# Drop unnecessary columns\ndf = df.drop(['car_ID', 'CarName'], axis=1)\n\n# Print basic info\nprint(\"Dataset shape:\", df.shape)\nprint(\"Missing values:\", df.isnull().sum().sum())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "72b783d1-db7e-4489-8bd4-6607e346238e",
      "cell_type": "code",
      "source": "# Encode categorical variables using Label Encoding (safe for tree models)\ndf_encoded = df.copy()\ncat_cols = df.select_dtypes(include='object').columns\n\nfor col in cat_cols:\n    le = LabelEncoder()\n    df_encoded[col] = le.fit_transform(df_encoded[col])\n\n# Separate features and target\nX = df_encoded.drop('price', axis=1)\ny = df_encoded['price']\n\n# Train-test split (80-20)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Scale for Linear Regression and SVR\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "514f58a7-f0a8-483c-9b18-d2a1c9faacba",
      "cell_type": "code",
      "source": "# ----------------------------\n# 3. TRAIN 5 REGRESSION MODELS\n# ----------------------------\nmodels = {}\n\n# 1. Linear Regression\nlr = LinearRegression()\nlr.fit(X_train_scaled, y_train)\nmodels['Linear Regression'] = (lr, X_test_scaled)\n\n# 2. Decision Tree\ndt = DecisionTreeRegressor(random_state=42)\ndt.fit(X_train, y_train)\nmodels['Decision Tree'] = (dt, X_test)\n\n# 3. Random Forest\nrf = RandomForestRegressor(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\nmodels['Random Forest'] = (rf, X_test)\n\n# 4. Gradient Boosting\ngb = GradientBoostingRegressor(n_estimators=100, random_state=42)\ngb.fit(X_train, y_train)\nmodels['Gradient Boosting'] = (gb, X_test)\n\n# 5. SVR (use moderate C for stability)\nsvr = SVR(kernel='rbf', C=10, gamma='scale')\nsvr.fit(X_train_scaled, y_train)\nmodels['SVR'] = (svr, X_test_scaled)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c73f1777-7942-469f-84b5-9d6cf003144e",
      "cell_type": "code",
      "source": "# ----------------------------\n# 4. EVALUATE MODELS\n# ----------------------------\nresults = []\nfor name, (model, X_test_used) in models.items():\n    y_pred = model.predict(X_test_used)\n    r2 = r2_score(y_test, y_pred)\n    mse = mean_squared_error(y_test, y_pred)\n    mae = mean_absolute_error(y_test, y_pred)\n    results.append([name, round(r2, 4), round(mse, 2), round(mae, 2)])\n\nresults_df = pd.DataFrame(results, columns=['Model', 'R²', 'MSE', 'MAE'])\nresults_df = results_df.sort_values(by='R²', ascending=False).reset_index(drop=True)\nresults_df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "14a9ef63-3970-42cd-86b0-428129a4fc1f",
      "cell_type": "code",
      "source": "### Model Comparison\n\n- **Best Model**: **Random Forest** (Highest R², lowest MSE/MAE)  \n- **Worst Model**: **SVR** (Struggles with mixed data types and limited tuning)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e68d8797-808a-4d73-97d4-7d194823cef1",
      "cell_type": "code",
      "source": "# ----------------------------\n# 5. FEATURE IMPORTANCE (Random Forest)\n# ----------------------------\nimportances = rf.feature_importances_\nfeature_names = X.columns\n\nimportance_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Importance': importances\n}).sort_values(by='Importance', ascending=False)\n\n# Plot top 10 features\nplt.figure(figsize=(10, 6))\nsns.barplot(data=importance_df.head(10), x='Importance', y='Feature')\nplt.title('Top 10 Features Influencing Car Price')\nplt.tight_layout()\nplt.show()\n\nimportance_df.head(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9f1963b5-57e3-4495-9d24-2ab1c5b2126f",
      "cell_type": "code",
      "source": "# ----------------------------\n# 6. HYPERPARAMETER TUNING (Random Forest)\n# ----------------------------\nparam_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [10, 20, None],\n    'min_samples_split': [2, 5]\n}\n\ngrid_search = GridSearchCV(\n    RandomForestRegressor(random_state=42),\n    param_grid,\n    cv=5,\n    scoring='r2',\n    n_jobs=-1\n)\ngrid_search.fit(X_train, y_train)\n\n# Evaluate tuned model\nbest_rf = grid_search.best_estimator_\ny_pred_tuned = best_rf.predict(X_test)\nr2_tuned = r2_score(y_test, y_pred_tuned)\nmae_tuned = mean_absolute_error(y_test, y_pred_tuned)\n\nprint(\"Best Parameters:\", grid_search.best_params_)\nprint(f\"Original R²: {results_df[results_df['Model']=='Random Forest']['R²'].values[0]}\")\nprint(f\"Tuned R²: {round(r2_tuned, 4)}\")\nprint(f\"Original MAE: {results_df[results_df['Model']=='Random Forest']['MAE'].values[0]}\")\nprint(f\"Tuned MAE: {round(mae_tuned, 2)}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f486c9a7-d7dd-42c9-b963-7d847be6e18b",
      "cell_type": "code",
      "source": "## Conclusion\n\n- **Random Forest** is the best model (R² > 0.95), capturing complex relationships in car pricing.\n- **Key drivers**: `brand`, `enginesize`, `curbweight`, `horsepower`, `carbody`.\n- **Hyperparameter tuning** slightly improved performance.\n- This model helps the company **design cars to hit target price points** in the US market.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}